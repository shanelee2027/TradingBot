{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as alpaca\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.historical.stock import StockHistoricalDataClient\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = True\n",
    "\n",
    "# initialize API from API keys in .env\n",
    "load_dotenv()\n",
    "\n",
    "if paper:\n",
    "    api_key = os.environ['APCA-API-PAPER-KEY-ID']\n",
    "    api_secret_key = os.environ['APCA-API-PAPER-SECRET-KEY']\n",
    "    api_base_url = 'https://paper-api.alpaca.markets'\n",
    "else:\n",
    "    api_key = os.environ['APCA-API-KEY-ID']\n",
    "    api_secret_key = os.environ['APCA-API-SECRET-KEY']\n",
    "    api_base_url = 'https://api.alpaca.markets'\n",
    "\n",
    "api = alpaca.REST(api_key, api_secret_key, api_base_url)\n",
    "account = api.get_account()\n",
    "trading_client = TradingClient(api_key, api_secret_key, paper=paper)\n",
    "data_client = StockHistoricalDataClient(api_key, api_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SP500():\n",
    "    market_caps = []\n",
    "    SP500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "    #SP500 = SP500[0:20]\n",
    "    for index, row in SP500.iterrows():\n",
    "        print(f\"{index}: {row['Symbol']}\")\n",
    "        query_attempts = 0\n",
    "        market_cap = 0\n",
    "        while (True):\n",
    "            query_attempts += 1\n",
    "            if query_attempts >= 3:\n",
    "                raise Exception('query failed')\n",
    "            try:\n",
    "                market_cap = yf.Ticker(row['Symbol']).info.get(\"marketCap\")\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(3)\n",
    "        market_caps.append(market_cap)\n",
    "        print(market_cap)\n",
    "        print()\n",
    "        time.sleep(1)\n",
    "    SP500[\"Market Cap\"] = market_caps\n",
    "    return SP500\n",
    "\n",
    "def get_SP(n=500):\n",
    "    return pd.read_csv('SP500.csv')[0:n].sort_values(by='Symbol')\n",
    "\n",
    "def get_weekly_stock_bars(symbols, start=dt.datetime(2019, 1, 1), filename='output.csv'):\n",
    "    request_params = StockBarsRequest(\n",
    "        symbol_or_symbols=symbols,\n",
    "        timeframe=TimeFrame.Day,\n",
    "        start=start,\n",
    "        adjustment='all'\n",
    "    )\n",
    "    bars = repeated_get_stock_bars(request_params)\n",
    "    df = bars.df\n",
    "    df = df[df.index.get_level_values('timestamp').day_name() == 'Friday']\n",
    "    df['log return'] = np.log(df['close'] / df['close'].groupby(level=0).shift(1))\n",
    "    df = df.dropna(subset=['log return'])\n",
    "    df = df[['close', 'log return']]\n",
    "    df = df.swaplevel('timestamp', 'symbol')\n",
    "    df = df.sort_index(level=['timestamp', 'symbol'], ascending=[True, True])\n",
    "\n",
    "    valid_symbols = df.groupby('symbol').size()\n",
    "    valid_symbols = valid_symbols[valid_symbols == df.index.get_level_values(level=0).nunique()].index\n",
    "    df = df[df.index.get_level_values(level=1).isin(valid_symbols)]\n",
    "    df.to_csv(filename)\n",
    "\n",
    "def repeated_get_stock_bars(request_params):\n",
    "    query_attempts = 0\n",
    "    while (True):\n",
    "        query_attempts += 1\n",
    "        if query_attempts >= 3:\n",
    "            raise Exception('query failed')\n",
    "        try:\n",
    "            return data_client.get_stock_bars(request_params)\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "\n",
    "def train_and_store_models(test_start_date='2022-01-01', test_end_date='2023-01-01'):\n",
    "    df = pd.read_csv('output.csv')\n",
    "    df_pivot = df.pivot(index='timestamp', columns='symbol', values='log return')\n",
    "    df_test_x = df_pivot[(df_pivot.index >= test_start_date) & (df_pivot.index <= test_end_date)]\n",
    "    df_train_x = df_pivot[(df_pivot.index < test_start_date) | (df_pivot.index > test_end_date)]\n",
    "    df_test_y = df_test_x.copy()\n",
    "    df_train_y = df_train_x.copy()\n",
    "\n",
    "    for symbol in df['symbol'].unique():\n",
    "        scaler = StandardScaler()\n",
    "        df_train_x.loc[:, symbol] = scaler.fit_transform(df_train_x[[symbol]]).astype(df_train_x[symbol].dtype)\n",
    "        df_test_x.loc[:, symbol] = scaler.transform(df_test_x[[symbol]]).astype(df_test_x[symbol].dtype)\n",
    "\n",
    "    models = {}\n",
    "    \n",
    "    for symbol in df['symbol'].unique():\n",
    "        print(f\"Training {symbol} model...\")\n",
    "        y_train = df_train_y[symbol].values\n",
    "        X_train = df_train_x.drop(symbol, axis=1)\n",
    "        y_test = df_test_y[symbol].values\n",
    "        X_test = df_test_x.drop(symbol, axis=1)\n",
    "\n",
    "        # Adjusted range for alpha and l1_ratio\n",
    "        param_grid = {\n",
    "            'alpha': [0.005, 0.01, 0.025, 0.05, 0.1, 0.25],  # Try smaller alpha values\n",
    "            'l1_ratio': [0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95]     # Try a mix between Ridge and Lasso\n",
    "        }\n",
    "\n",
    "        # Set up the ElasticNet model\n",
    "        elasticnet = ElasticNet()\n",
    "\n",
    "        # Perform grid search with 5-fold cross-validation\n",
    "        grid_search = GridSearchCV(elasticnet, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best parameters found\n",
    "        best_alpha = grid_search.best_params_['alpha']\n",
    "        best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "        print(f\"Best alpha: {best_alpha}, Best l1_ratio: {best_l1_ratio}\")\n",
    "\n",
    "        # Fit the ElasticNet model with the best parameters found\n",
    "        model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "        model.fit(X_train, y_train)\n",
    "        models[symbol] = model\n",
    "    joblib.dump(models, 'stock_models.pkl')\n",
    "\n",
    "def test_model(symbol, test_start_date='2022-01-01', test_end_date='2023-01-01'):\n",
    "    # Load the models\n",
    "    loaded_models = joblib.load('stock_models.pkl')\n",
    "\n",
    "    # Access a specific model\n",
    "    model = loaded_models[symbol]\n",
    "\n",
    "    df = pd.read_csv('output.csv')\n",
    "    df_pivot = df.pivot(index='timestamp', columns='symbol', values='log return')\n",
    "    df_test_x = df_pivot[(df_pivot.index >= test_start_date) & (df_pivot.index <= test_end_date)]\n",
    "    df_train_x = df_pivot[(df_pivot.index < test_start_date) | (df_pivot.index > test_end_date)]\n",
    "    df_test_y = df_test_x.copy()\n",
    "    df_train_y = df_train_x.copy()\n",
    "\n",
    "    for symbol2 in df['symbol'].unique():\n",
    "        scaler = StandardScaler()\n",
    "        df_train_x.loc[:, symbol2] = scaler.fit_transform(df_train_x[[symbol2]]).astype(df_train_x[symbol2].dtype)\n",
    "        df_test_x.loc[:, symbol2] = scaler.transform(df_test_x[[symbol2]]).astype(df_test_x[symbol2].dtype)\n",
    "    \n",
    "    y_test = df_test_y[symbol].values\n",
    "    X_test = df_test_x.drop(symbol, axis=1)\n",
    "\n",
    "    # Assuming `X_train.columns` contains the stock symbols\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Stock Symbol': X_test.columns, \n",
    "        'Coefficient': model.coef_\n",
    "    })\n",
    "\n",
    "    # Sort by absolute value to highlight the most impactful stocks\n",
    "    coef_df_sorted = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "    print(coef_df_sorted)\n",
    "    coef_df_sorted.to_csv('model_coefs.csv')\n",
    "    # Example prediction\n",
    "    y_pred = model.predict(X_test)\n",
    "    plt.scatter(x=y_test, y=y_pred)\n",
    "    plt.plot(y_pred, y_pred, color='red', label='y=x')\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SP50 = get_SP(100)\n",
    "#get_weekly_stock_bars(SP50['Symbol'], start=dt.datetime(2016, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_and_store_models()\n",
    "test_model('XOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
