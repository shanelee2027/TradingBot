{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as alpaca\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.historical.stock import StockHistoricalDataClient\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = True\n",
    "\n",
    "# initialize API from API keys in .env\n",
    "load_dotenv()\n",
    "\n",
    "if paper:\n",
    "    api_key = os.environ['APCA-API-PAPER-KEY-ID']\n",
    "    api_secret_key = os.environ['APCA-API-PAPER-SECRET-KEY']\n",
    "    api_base_url = 'https://paper-api.alpaca.markets'\n",
    "else:\n",
    "    api_key = os.environ['APCA-API-KEY-ID']\n",
    "    api_secret_key = os.environ['APCA-API-SECRET-KEY']\n",
    "    api_base_url = 'https://api.alpaca.markets'\n",
    "\n",
    "api = alpaca.REST(api_key, api_secret_key, api_base_url)\n",
    "account = api.get_account()\n",
    "trading_client = TradingClient(api_key, api_secret_key, paper=paper)\n",
    "data_client = StockHistoricalDataClient(api_key, api_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SP500():\n",
    "    market_caps = []\n",
    "    SP500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "    #SP500 = SP500[0:20]\n",
    "    for index, row in SP500.iterrows():\n",
    "        print(f\"{index}: {row['Symbol']}\")\n",
    "        query_attempts = 0\n",
    "        market_cap = 0\n",
    "        while (True):\n",
    "            query_attempts += 1\n",
    "            if query_attempts >= 3:\n",
    "                raise Exception('query failed')\n",
    "            try:\n",
    "                market_cap = yf.Ticker(row['Symbol']).info.get(\"marketCap\")\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(3)\n",
    "        market_caps.append(market_cap)\n",
    "        print(market_cap)\n",
    "        print()\n",
    "        time.sleep(1)\n",
    "    SP500[\"Market Cap\"] = market_caps\n",
    "    return SP500\n",
    "\n",
    "def get_SP(n=500):\n",
    "    return pd.read_csv('SP500.csv')[0:n].sort_values(by='Symbol')\n",
    "\n",
    "def get_weekly_stock_bars(symbols, start=dt.datetime(2019, 1, 1), filename='output.csv'):\n",
    "    request_params = StockBarsRequest(\n",
    "        symbol_or_symbols=symbols,\n",
    "        timeframe=TimeFrame.Day,\n",
    "        start=start,\n",
    "        adjustment='all'\n",
    "    )\n",
    "    bars = repeated_get_stock_bars(request_params)\n",
    "    df = bars.df\n",
    "    df = df[df.index.get_level_values('timestamp').day_name() == 'Friday']\n",
    "    df['log return'] = np.log(df['close'] / df['close'].groupby(level=0).shift(1))\n",
    "    df = df.dropna(subset=['log return'])\n",
    "    df = df[['close', 'log return']]\n",
    "    df = df.swaplevel('timestamp', 'symbol')\n",
    "    df = df.sort_index(level=['timestamp', 'symbol'], ascending=[True, True])\n",
    "\n",
    "    valid_symbols = df.groupby('symbol').size()\n",
    "    valid_symbols = valid_symbols[valid_symbols == df.index.get_level_values(level=0).nunique()].index\n",
    "    df = df[df.index.get_level_values(level=1).isin(valid_symbols)]\n",
    "    df.to_csv(filename)\n",
    "\n",
    "def repeated_get_stock_bars(request_params):\n",
    "    query_attempts = 0\n",
    "    while (True):\n",
    "        query_attempts += 1\n",
    "        if query_attempts >= 3:\n",
    "            raise Exception('query failed')\n",
    "        try:\n",
    "            return data_client.get_stock_bars(request_params)\n",
    "        except:\n",
    "            time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP50 = get_SP(100)\n",
    "get_weekly_stock_bars(SP50['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv')\n",
    "display(df)\n",
    "plt.scatter(x=df[df['symbol'] == 'AAPL']['timestamp'], y=df[df['symbol'] == 'AAPL']['log return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df.pivot(index='timestamp', columns='symbol', values='log return')\n",
    "y = df_pivot['NVDA'].values\n",
    "X = df_pivot.drop('NVDA', axis=1)\n",
    "X = X.to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Adjusted range for alpha and l1_ratio\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.005, 0.01, 0.05, 0.1],  # Try smaller alpha values\n",
    "    'l1_ratio': [0.05, 0.1, 0.2, 0.35, 0.5, 0.65, 0.8, 0.9, 0.95]     # Try a mix between Ridge and Lasso\n",
    "}\n",
    "\n",
    "# Set up the ElasticNet model\n",
    "elasticnet = ElasticNet()\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(elasticnet, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
    "print(f\"Best alpha: {best_alpha}, Best l1_ratio: {best_l1_ratio}\")\n",
    "\n",
    "# Fit the ElasticNet model with the best parameters found\n",
    "model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate with Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error with best parameters: {mse:.4f}')\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'model.pkl')\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "results = pd.DataFrame({'True Values': y_test, 'Predictions': y_pred})\n",
    "results.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.read_csv('predictions.csv')\n",
    "display(preds)\n",
    "plt.scatter(x=preds['True Values'], y=preds['Predictions'])\n",
    "r2 = r2_score(preds['True Values'], preds['Predictions'])\n",
    "print(r2)\n",
    "mape = np.mean(np.abs(preds['True Values'] - preds['Predictions']) / preds['True Values']) * 100\n",
    "print(f\"Mean Absolute Percentage Error: {mape:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
